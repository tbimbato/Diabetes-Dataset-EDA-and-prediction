{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model for diabetes dataset\n",
    "\n",
    "This notebook assumes the use of the cleaned dataset (notebook EDA.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('../datasets/diabetes_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define target and features\n",
    "target_feature = 'CLASS'\n",
    "X = data.drop(columns=[target_feature])\n",
    "y = data[target_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize the features\n",
    "'''\n",
    "StandardScaler perform standardization by removing the mean and scaling to unit variance.\n",
    "This means that every feature will have a mean of 0 and a standard deviation of 1.\n",
    "'''\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# plot the distribution of the features after normalization\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(X_scaled.shape[1]):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    sns.histplot(X_scaled[:, i], kde=True)\n",
    "    plt.title(X.columns[i])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train a chosen model using a chosen splitting method, then use it to predict a single new patient\n",
    "# Method can be 'holdout' or 'kfold'\n",
    "\n",
    "def predict_patient(patient_data, model_name='Logistic Regression', split_method='holdout'):\n",
    "    model = models[model_name]\n",
    "    if split_method == 'holdout':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "    elif split_method == 'kfold':\n",
    "        for train_index, test_index in skf.split(X_scaled, y):\n",
    "            X_train, y_train = X_scaled[train_index], y.iloc[train_index]\n",
    "            model.fit(X_train, y_train)\n",
    "            break  # Just train on the first fold\n",
    "    else:\n",
    "        raise ValueError(\"Unknown split method. Use 'holdout' or 'kfold'.\")\n",
    "\n",
    "    # Scale the patient input with the same scaler\n",
    "    patient_array = scaler.transform([patient_data.values])\n",
    "    prediction = model.predict(patient_array)[0]\n",
    "    probability = model.predict_proba(patient_array)[0][prediction]\n",
    "    output = list([prediction, probability])\n",
    "    print(f\"Prediction: {'Diabetic' if output[0] == 1 else 'Non-diabetic'}, Probability: {output[1]*100:.2f}%\")\n",
    "\n",
    "\n",
    "    retunr output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function to evaluate models \n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Evaluate the model using confusion matrix, classification report, and accuracy score.\n",
    "    Inputs:\n",
    "        model: The machine learning model to evaluate.\n",
    "        X_train: Training features.\n",
    "        X_test: Testing features.\n",
    "        y_train: Training labels.\n",
    "        y_test: Testing labels.\n",
    "    Outputs:\n",
    "        None\n",
    "        (just prints the evaluation metrics)\n",
    "    '''\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SPLIT METHOD 1: SIMPLE HOLDOUT ---\n",
    "print(\"\\n===== Holdout Split Evaluation =====\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    evaluate_model(model, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SPLIT METHOD 2: STRATIFIED K-FOLD CROSS-VALIDATION ---\n",
    "# This method splits the dataset into K folds (here, 5), preserving class distribution in each fold\n",
    "print(\"\\n===== Stratified K-Fold Cross-Validation =====\")\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate models fold-by-fold using evaluate_model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    fold_idx = 1\n",
    "    accuracies = []\n",
    "    for train_index, test_index in skf.split(X_scaled, y):\n",
    "        print(f\"\\n--- Fold {fold_idx} ---\")\n",
    "        X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        evaluate_model(model, X_train_fold, X_test_fold, y_train_fold, y_test_fold)\n",
    "        fold_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VISUALIZE PREDICTIONS ===\n",
    "# Plot confusion matrix as heatmap for any model\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for each method\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    plot_confusion_matrix(y_test, y_pred, title=f\"Confusion Matrix - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PREDICTION INTERFACE FUNCTIONS ===\n",
    "\n",
    "# Function to allow the user to input values for each feature (except the target) to simulate a patient\n",
    "# Returns a pandas Series that can be used as input for a model\n",
    "\n",
    "# Function to create a patient input by asking the user, validating suspicious and general values\n",
    "def create_patient_input(feature_names):\n",
    "    print(\"\\nPlease enter values for the following features:\")\n",
    "    data = {}\n",
    "    for feature in feature_names:\n",
    "        col_min = X[feature].min()\n",
    "        col_max = X[feature].max()\n",
    "        print(f\"{feature} (valid range: {round(col_min, 2)} - {round(col_max, 2)})\")\n",
    "        while True:\n",
    "            try:\n",
    "                value = float(input(f\"Enter value for {feature}: \"))\n",
    "                if col_min <= value <= col_max:\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Value out of range. Please enter a value between {col_min} and {col_max}.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number.\")\n",
    "        data[feature] = value\n",
    "    return pd.Series(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example: Create Patient Input ===\n",
      "\n",
      "Please enter values for the following features:\n",
      "Gender (valid range: 0 - 1)\n",
      "AGE (valid range: 25.0 - 79.0)\n",
      "Urea (valid range: 1.1 - 22.0)\n",
      "Value out of range. Please enter a value between 1.1 and 22.0.\n",
      "Cr (valid range: 20.0 - 370.0)\n",
      "HbA1c (valid range: 0.9 - 16.0)\n",
      "Chol (valid range: 0.0 - 10.3)\n",
      "TG (valid range: 0.3 - 8.7)\n",
      "HDL (valid range: 0.4 - 5.0)\n",
      "LDL (valid range: 0.3 - 9.9)\n",
      "VLDL (valid range: 0.1 - 3.5)\n",
      "BMI (valid range: 19.0 - 47.75)\n",
      "\n",
      "Patient Data:\n",
      "Gender      1.0\n",
      "AGE        29.0\n",
      "Urea       10.0\n",
      "Cr        200.0\n",
      "HbA1c      10.0\n",
      "Chol        9.0\n",
      "TG          1.0\n",
      "HDL         2.0\n",
      "LDL         2.0\n",
      "VLDL        1.0\n",
      "BMI        30.0\n",
      "dtype: float64\n",
      "\n",
      "Prediction: Diabetic\n",
      "Prediction result: Diabetic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/eda_env/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Example: Create Patient Input ===\")\n",
    "patient_data = create_patient_input(X.columns)\n",
    "print(\"\\nPatient Data:\")\n",
    "print(patient_data)\n",
    "# Predict the class for the created patient data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Non-diabetic, Probability: 70.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/eda_env/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Select a patient from the dataset who does not have diabetes (CLASS = 0)\n",
    "non_diabetic_patient = data[data[target_feature] == 0].iloc[0].drop(target_feature)\n",
    "\n",
    "# Predict the class for the selected patient\n",
    "prediction = predict_patient(non_diabetic_patient, model_name='Logistic Regression', split_method='holdout')\n",
    "print(f\"Prediction: {'Diabetic' if prediction[0] == 1 else 'Non-diabetic'}, Probability: {prediction[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to train a chosen model using a chosen splitting method, then use it to predict a single new patient\n",
    "# Method can be 'holdout' or 'kfold'\n",
    "\n",
    "def predict_patient(patient_data, model_name='Logistic Regression', split_method='holdout'):\n",
    "    model = models[model_name]\n",
    "    if split_method == 'holdout':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "    elif split_method == 'kfold':\n",
    "        for train_index, test_index in skf.split(X_scaled, y):\n",
    "            X_train, y_train = X_scaled[train_index], y.iloc[train_index]\n",
    "            model.fit(X_train, y_train)\n",
    "            break  # Just train on the first fold\n",
    "    else:\n",
    "        raise ValueError(\"Unknown split method. Use 'holdout' or 'kfold'.\")\n",
    "\n",
    "    # Scale the patient input with the same scaler\n",
    "    patient_array = scaler.transform([patient_data.values])\n",
    "    prediction = model.predict(patient_array)[0]\n",
    "    print(f\"\\nPrediction: {'Diabetic' if prediction == 1 else 'Non-diabetic'}\")\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Precision**: Measures how many of the positive predictions were actually correct.\n",
    "  - Formula: TruePositives / (TruePositives + FalsePositives)\n",
    "  - High precision means few false positives.\n",
    "  - Example: If a model predicts 100 patients as diabetic and 90 are truly diabetic, precision is 0.90.\n",
    "\n",
    "- **Recall (Sensitivity)**: Measures how many actual positive cases were correctly predicted.\n",
    "  - Formula: TruePositives / (TruePositives + FalseNegative)\n",
    "  - High recall means few false negatives.\n",
    "  - Example: If there are 100 diabetic patients and the model finds 95 of them, recall is 0.95.\n",
    "\n",
    "- **F1-Score**: Harmonic mean of precision and recall. A balanced metric when classes are imbalanced.\n",
    "  - Formula: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "  - Useful when you care equally about precision and recall.\n",
    "\n",
    "- **Support**: The number of actual samples for each class in the test set.\n",
    "  - Helps interpret performance per class.\n",
    "\n",
    "- **Accuracy**: Overall, how often is the classifier correct?\n",
    "  - Formula: (TruePositives + TrueNegative) / (Total predictions)\n",
    "\n",
    "- **Macro avg**: Average of precision, recall, and F1-score calculated independently for each class.\n",
    "  - Treats all classes equally.\n",
    "\n",
    "- **Weighted avg**: Same as macro avg, but each class's score is weighted by its support.\n",
    "  - More informative when classes are imbalanced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
