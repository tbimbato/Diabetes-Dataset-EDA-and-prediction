{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Dataset - EDA\n",
    "\n",
    "In this notebook, an initial Exploratory Data Analysis (EDA) is performed, followed by data cleaning and the plotting of insights related to the data contained in the dataset `diabetes_unclean.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and First look\n",
    "In this section, the necessary libraries are imported, and a preliminary analysis of the dataset is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datasets/diabetes_unclean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "No_Pation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AGE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Urea",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HbA1c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Chol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TG",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HDL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LDL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VLDL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CLASS",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "61181555-962b-4be1-8024-54146adf4a68",
       "rows": [
        [
         "0",
         "502",
         "17975",
         "F",
         "50.0",
         "4.7",
         "46.0",
         "4.9",
         "4.2",
         "0.9",
         "2.4",
         "1.4",
         "0.5",
         "24.0",
         "N"
        ],
        [
         "1",
         "735",
         "34221",
         "M",
         "26.0",
         "4.5",
         "62.0",
         "4.9",
         "3.7",
         "1.4",
         "1.1",
         "2.1",
         "0.6",
         "23.0",
         "N"
        ],
        [
         "2",
         "420",
         "47975",
         "F",
         "50.0",
         "4.7",
         "46.0",
         "4.9",
         "4.2",
         "0.9",
         "2.4",
         "1.4",
         "0.5",
         "24.0",
         "N"
        ],
        [
         "3",
         "680",
         "87656",
         "F",
         "50.0",
         "4.7",
         "46.0",
         "4.9",
         "4.2",
         "0.9",
         "2.4",
         "1.4",
         "0.5",
         "24.0",
         "N"
        ],
        [
         "4",
         "504",
         "34223",
         "M",
         "33.0",
         "7.1",
         "46.0",
         "4.9",
         "4.9",
         "1.0",
         "0.8",
         "2.0",
         "0.4",
         "21.0",
         "N"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>No_Pation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Urea</th>\n",
       "      <th>Cr</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Chol</th>\n",
       "      <th>TG</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>VLDL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502</td>\n",
       "      <td>17975</td>\n",
       "      <td>F</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>735</td>\n",
       "      <td>34221</td>\n",
       "      <td>M</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>47975</td>\n",
       "      <td>F</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>680</td>\n",
       "      <td>87656</td>\n",
       "      <td>F</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>34223</td>\n",
       "      <td>M</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  No_Pation Gender   AGE  Urea    Cr  HbA1c  Chol   TG  HDL  LDL  VLDL  \\\n",
       "0  502      17975      F  50.0   4.7  46.0    4.9   4.2  0.9  2.4  1.4   0.5   \n",
       "1  735      34221      M  26.0   4.5  62.0    4.9   3.7  1.4  1.1  2.1   0.6   \n",
       "2  420      47975      F  50.0   4.7  46.0    4.9   4.2  0.9  2.4  1.4   0.5   \n",
       "3  680      87656      F  50.0   4.7  46.0    4.9   4.2  0.9  2.4  1.4   0.5   \n",
       "4  504      34223      M  33.0   7.1  46.0    4.9   4.9  1.0  0.8  2.0   0.4   \n",
       "\n",
       "    BMI CLASS  \n",
       "0  24.0     N  \n",
       "1  23.0     N  \n",
       "2  24.0     N  \n",
       "3  24.0     N  \n",
       "4  21.0     N  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID' 'No_Pation' 'Gender' 'AGE' 'Urea' 'Cr' 'HbA1c' 'Chol' 'TG' 'HDL'\n",
      " 'LDL' 'VLDL' 'BMI' 'CLASS']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset features\n",
    "In the dataset we can access the following feature:\n",
    "\n",
    "- **Gender**: The gender of the individual (e.g., Male, Female).\n",
    "- **AGE**: The age of the individual in years.\n",
    "- **Urea**: The level of urea in the blood, indicating kidney function. \n",
    "- **Cr**: Creatinine level in the blood, used to assess kidney function.\n",
    "- **HbA1c**: Hemoglobin A1c percentage, a measure of average blood sugar levels.\n",
    "- **Chol**: Total cholesterol level in the blood, measured in mmol/L, indicating lipid profile.\n",
    "- **TG**: Triglycerides level in the blood, measured in mmol/L, another component of the lipid profile.\n",
    "- **HDL**: High-Density Lipoprotein cholesterol, often referred to as \"good cholesterol,\" measured in mmol/L.\n",
    "- **LDL**: Low-Density Lipoprotein cholesterol, often referred to as \"bad cholesterol,\" measured in mmol/L.\n",
    "- **VLDL**: Very Low-Density Lipoprotein cholesterol, another type of \"bad cholesterol,\" measured in mmol/L.\n",
    "- **BMI**: Body Mass Index, a measure of body fat based on height and weight.\n",
    "- **CLASS**: The target variable indicating the presence or absence of diabetes (e.g., diabetic or non-diabetic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1009 entries, 0 to 1008\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         1009 non-null   int64  \n",
      " 1   No_Pation  1009 non-null   int64  \n",
      " 2   Gender     1009 non-null   object \n",
      " 3   AGE        1008 non-null   float64\n",
      " 4   Urea       1008 non-null   float64\n",
      " 5   Cr         1007 non-null   float64\n",
      " 6   HbA1c      1006 non-null   float64\n",
      " 7   Chol       1007 non-null   float64\n",
      " 8   TG         1007 non-null   float64\n",
      " 9   HDL        1008 non-null   float64\n",
      " 10  LDL        1007 non-null   float64\n",
      " 11  VLDL       1008 non-null   float64\n",
      " 12  BMI        1009 non-null   float64\n",
      " 13  CLASS      1009 non-null   object \n",
      "dtypes: float64(10), int64(2), object(2)\n",
      "memory usage: 110.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "No_Pation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AGE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Urea",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HbA1c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Chol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TG",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HDL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LDL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VLDL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4f9b360e-1047-413e-bafe-32fe607ba34c",
       "rows": [
        [
         "count",
         "1009.0",
         "1009.0",
         "1008.0",
         "1008.0",
         "1007.0",
         "1006.0",
         "1007.0",
         "1007.0",
         "1008.0",
         "1007.0",
         "1008.0",
         "1009.0"
        ],
        [
         "mean",
         "339.1615460852329",
         "271744.7760158573",
         "53.620039682539684",
         "5.131094246031746",
         "68.97318768619662",
         "8.284155069582505",
         "4.863872889771599",
         "2.3487686196623634",
         "1.2042162698412697",
         "2.610119165839126",
         "1.8505952380952382",
         "29.589910802775027"
        ],
        [
         "std",
         "239.73816874159922",
         "3365681.345427762",
         "8.740974928434246",
         "2.9311359057811552",
         "59.81329695902805",
         "2.5335761271076693",
         "1.297326389603986",
         "1.397486764711252",
         "0.6581583200367065",
         "1.1160946118517339",
         "3.6498588133454772",
         "4.9462458599543275"
        ],
        [
         "min",
         "1.0",
         "123.0",
         "25.0",
         "0.5",
         "6.0",
         "0.9",
         "0.0",
         "0.3",
         "0.2",
         "0.3",
         "0.1",
         "19.0"
        ],
        [
         "25%",
         "127.0",
         "24065.0",
         "51.0",
         "3.7",
         "48.0",
         "6.5",
         "4.0",
         "1.5",
         "0.9",
         "1.8",
         "0.7",
         "26.0"
        ],
        [
         "50%",
         "296.0",
         "34399.0",
         "55.0",
         "4.6",
         "60.0",
         "8.0",
         "4.8",
         "2.0",
         "1.1",
         "2.5",
         "0.9",
         "30.0"
        ],
        [
         "75%",
         "548.0",
         "45390.0",
         "59.0",
         "5.7",
         "73.0",
         "10.2",
         "5.6",
         "2.9",
         "1.3",
         "3.3",
         "1.5",
         "33.0"
        ],
        [
         "max",
         "800.0",
         "75435657.0",
         "79.0",
         "38.9",
         "800.0",
         "16.0",
         "10.3",
         "13.8",
         "9.9",
         "9.9",
         "35.0",
         "47.75"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>No_Pation</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Urea</th>\n",
       "      <th>Cr</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Chol</th>\n",
       "      <th>TG</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>VLDL</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1009.000000</td>\n",
       "      <td>1.009000e+03</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>1006.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>339.161546</td>\n",
       "      <td>2.717448e+05</td>\n",
       "      <td>53.620040</td>\n",
       "      <td>5.131094</td>\n",
       "      <td>68.973188</td>\n",
       "      <td>8.284155</td>\n",
       "      <td>4.863873</td>\n",
       "      <td>2.348769</td>\n",
       "      <td>1.204216</td>\n",
       "      <td>2.610119</td>\n",
       "      <td>1.850595</td>\n",
       "      <td>29.589911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>239.738169</td>\n",
       "      <td>3.365681e+06</td>\n",
       "      <td>8.740975</td>\n",
       "      <td>2.931136</td>\n",
       "      <td>59.813297</td>\n",
       "      <td>2.533576</td>\n",
       "      <td>1.297326</td>\n",
       "      <td>1.397487</td>\n",
       "      <td>0.658158</td>\n",
       "      <td>1.116095</td>\n",
       "      <td>3.649859</td>\n",
       "      <td>4.946246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.230000e+02</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>127.000000</td>\n",
       "      <td>2.406500e+04</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>3.439900e+04</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>548.000000</td>\n",
       "      <td>4.539000e+04</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>7.543566e+07</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>47.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID     No_Pation          AGE         Urea           Cr  \\\n",
       "count  1009.000000  1.009000e+03  1008.000000  1008.000000  1007.000000   \n",
       "mean    339.161546  2.717448e+05    53.620040     5.131094    68.973188   \n",
       "std     239.738169  3.365681e+06     8.740975     2.931136    59.813297   \n",
       "min       1.000000  1.230000e+02    25.000000     0.500000     6.000000   \n",
       "25%     127.000000  2.406500e+04    51.000000     3.700000    48.000000   \n",
       "50%     296.000000  3.439900e+04    55.000000     4.600000    60.000000   \n",
       "75%     548.000000  4.539000e+04    59.000000     5.700000    73.000000   \n",
       "max     800.000000  7.543566e+07    79.000000    38.900000   800.000000   \n",
       "\n",
       "             HbA1c         Chol           TG          HDL          LDL  \\\n",
       "count  1006.000000  1007.000000  1007.000000  1008.000000  1007.000000   \n",
       "mean      8.284155     4.863873     2.348769     1.204216     2.610119   \n",
       "std       2.533576     1.297326     1.397487     0.658158     1.116095   \n",
       "min       0.900000     0.000000     0.300000     0.200000     0.300000   \n",
       "25%       6.500000     4.000000     1.500000     0.900000     1.800000   \n",
       "50%       8.000000     4.800000     2.000000     1.100000     2.500000   \n",
       "75%      10.200000     5.600000     2.900000     1.300000     3.300000   \n",
       "max      16.000000    10.300000    13.800000     9.900000     9.900000   \n",
       "\n",
       "              VLDL          BMI  \n",
       "count  1008.000000  1009.000000  \n",
       "mean      1.850595    29.589911  \n",
       "std       3.649859     4.946246  \n",
       "min       0.100000    19.000000  \n",
       "25%       0.700000    26.000000  \n",
       "50%       0.900000    30.000000  \n",
       "75%       1.500000    33.000000  \n",
       "max      35.000000    47.750000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "In this section, data cleaning is performed by analyzing entries that are outside the acceptable range or are potential outliers. Additionally, preprocessing and encoding of non-numeric or categorical features are carried out.\n",
    "\n",
    "\n",
    "List of task to be performed in this section:\n",
    "- Backup the original dataset\n",
    "- Check for Null values\n",
    "- Conversion to numerical values or one-hot encoding of the 'object' or 'string' types\n",
    "- Check for outliers and cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_backup = dataset.copy()\n",
    "ds_backup.to_csv('../datasets/diabetes_unclean_backup.csv', index=False) # This saves a backup of the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "No_Pation    0\n",
       "Gender       0\n",
       "AGE          1\n",
       "Urea         1\n",
       "Cr           2\n",
       "HbA1c        3\n",
       "Chol         2\n",
       "TG           2\n",
       "HDL          1\n",
       "LDL          2\n",
       "VLDL         1\n",
       "BMI          0\n",
       "CLASS        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of missing values in each column\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null values \n",
    "Since the total entries of the dataset are 1009 and the Null values are less than the 2% of the dataset it is possible to remove them (no fill required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the rows with missing values and applying the changes to the dataset\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             int64\n",
       "No_Pation      int64\n",
       "Gender        object\n",
       "AGE          float64\n",
       "Urea         float64\n",
       "Cr           float64\n",
       "HbA1c        float64\n",
       "Chol         float64\n",
       "TG           float64\n",
       "HDL          float64\n",
       "LDL          float64\n",
       "VLDL         float64\n",
       "BMI          float64\n",
       "CLASS         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to be converted or encoded:\n",
    "- Gender -> simple encoding [0 = 'M', 1 = 'F']\n",
    "- Class -> simple encoding [0 = non-positive, 1 = positive]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'M', 'f'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are inconsistencies in the gender column we will perform a 'normalization' of the data and a conversion to numeric value \n",
    "```\n",
    "[0: Male, 1: Female]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repairing inconsistent values and Encoding of the 'Gender' column\n",
    "dataset['Gender'] = dataset['Gender'].str.upper().map({'M': 0, 'F': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'N ', 'P', 'Y', 'Y '], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['CLASS'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are several unique values with inconsistent syntax, since the possible value of the column `CLASS` are 'Diabetic' or 'Not Diabetic' we will encode it with the following syntax:\n",
    "```\n",
    "[Positive to diabetes: 1]\n",
    "[Negative to diabetes: 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding of the 'CLASS' column\n",
    "# 1. remove unwanted spaces\n",
    "dataset['CLASS'] = dataset['CLASS'].str.strip()\n",
    "# 2. raise all values to upper case\n",
    "dataset['CLASS'] = dataset['CLASS'].str.upper()\n",
    "# 3. make the values consistent (e.g. P means positive as well as Y, instead, N means negative or simply No)\n",
    "dataset['CLASS'] = dataset['CLASS'].replace({'P': 'Y'})\n",
    "\n",
    "# check:\n",
    "#Â dataset['CLASS'].unique()\n",
    "\n",
    "# 4. Encoding of the 'CLASS' column\n",
    "dataset['CLASS'] = dataset['CLASS'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unused columns\n",
    "Some columns are not relevant to predict diabetes. For example, columns like `ID` and `No_Pation` do not provide meaningful information for prediction and can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unused columns\n",
    "#Â backup of the cleaned and encoded dataset\n",
    "ds_backup = dataset.copy()\n",
    "#Â removing unused columns\n",
    "dataset.drop(columns=['ID', 'No_Pation'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes (CLASS = 1):\n",
      "Count: 891, Percentage: 89.64%\n",
      "\n",
      "No Diabetes (CLASS = 0):\n",
      "Count: 103, Percentage: 10.36%\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each class\n",
    "class_counts = dataset['CLASS'].value_counts()\n",
    "\n",
    "# Calculate the percentage\n",
    "class_percentages = (class_counts / len(dataset)) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Diabetes (CLASS = 1):\")\n",
    "print(f\"Count: {class_counts[1]}, Percentage: {class_percentages[1]:.2f}%\")\n",
    "print(\"\\nNo Diabetes (CLASS = 0):\")\n",
    "print(f\"Count: {class_counts[0]}, Percentage: {class_percentages[0]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot of the features to get an overall view of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x11f526000>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.pairplot(dataset, diag_kind='kde', hue='CLASS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "In this section, we identify outliers to ensure the dataset is consistent, enabling accurate analysis and reliable predictions using future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = dataset.drop(columns=['Gender', 'AGE']).describe() \n",
    "# storing the stats in a dataframe (excluding gender and age columns)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Filtering columns with a standard deviation greater than half the mean and store it in a list\n",
    "(retrieved from the just made 'stats' dataframe) \n",
    "'''\n",
    "\n",
    "\n",
    "# Boolean mask to filter columns: \n",
    "high_std_mask = stats.loc['std'] > (stats.loc['mean'] / 2)\n",
    "# Apply the mask and create a list of 'suspicious' features:\n",
    "features_high_std = stats.columns[high_std_mask] \n",
    "suspicious_features = list(features_high_std)\n",
    "print(suspicious_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of the features as subplots horizontally\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "# Loop through each feature and create a subplot: \n",
    "# i is the index of the feature in the dataset, feature is the name of the feature\n",
    "for i, feature in enumerate(dataset.columns, 1):\n",
    "    plt.subplot(len(dataset.columns), 1, i)         # Arrange subplots vertically\n",
    "    sns.boxplot(data=dataset[feature], orient='h')  # Set orientation to horizontal\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection Analysis\n",
    "\n",
    "## Features Requiring Special Attention\n",
    "\n",
    "As shown in the preliminary analysis, the features **'Urea', 'Cr', 'TG', 'HDL',** and **'VLDL'** show high values of standard deviation ($\\sigma$). Specifically, these columns have standard deviation values higher than half their respective means:\n",
    "\n",
    "$$\\text{Attention required when:}\\quad \\sigma > \\frac{\\text{mean}}{2}$$\n",
    "\n",
    "This indicates potential outliers that warrant further investigation.\n",
    "\n",
    "## Physiological Limits for Outlier Detection\n",
    "\n",
    "Physiological ranges and limits:\n",
    "\n",
    "| Feature | Lower Limit | Upper Limit | Justification |\n",
    "|---------|-------------|-------------|---------------|\n",
    "| **Urea** | 1 mmol/L | 25 mmol/L | Values outside this range are extremely rare in living patients and likely represent measurement errors |\n",
    "| **Cr (Creatinine)** | 10 Âµmol/L | 400 Âµmol/L | Values above 400 Âµmol/L may indicate severe renal failure but could also be data entry errors; values below 10 Âµmol/L are biologically implausible |\n",
    "| **TG (Triglycerides)** | 0.1 mmol/L | 10 mmol/L | While normal range is <1.7 mmol/L, values up to 10 mmol/L can occur in severe hypertriglyceridemia or **diabetic** patients |\n",
    "| **HDL** | 0.3 mmol/L | 5 mmol/L | Values above 5 mmol/L are highly improbable and likely due to laboratory errors or data entry mistakes |\n",
    "| **VLDL** | 0.05 mmol/L | ? mmol/L | Value derived from a medical equation that considers the levels of TG and cholesterol in the blood. Further investigation needed, possible syntethic values not needed for this project. |\n",
    "\n",
    "\n",
    "  *! Diclaimer*: The reference values provided are not intended for medical purposes and were obtained through online research. They are not guaranteed to be reliable or representative of the sample in question, as this is not the primary objective of the project.\n",
    "  Sources: https://www.scymed.com, https://www.my-personaltrainer.it/salute/conversione-colesterolo.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box-plot of the suspicious feature:\n",
    "In the box-plot above, it's evident that features such as 'Urea', 'Cr', 'TG', 'HDL', and 'VLDL' exhibit substantial variance with an asymmetric skew towards the upper extremes. However, we can't straightforwardly discard data above the third quartile since these patients might be suffering from diabetes-related pathologies or severe dysfunctions, information that could be needed in the prediction model and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting and storing in lists the upper and lower limits for each suspicious feature:\n",
    "#                   Urea, Cr,  TG, HDL, VLDL\n",
    "temp_limits_upper = [25,  400, 10,  5,   40 ]\n",
    "temp_limits_lower = [1,   10,  0.1, 0.3, 0.05]\n",
    "\n",
    "# converting it to a dataframe for better readability:\n",
    "suspicious_features_boundaries = pd.DataFrame({'Feature': suspicious_features, 'Upper Limit': temp_limits_upper, 'Lower Limit': temp_limits_lower})\n",
    "\n",
    "suspicious_features_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identification of the values that exceed the biological plausibility thresholds and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plotting the same boxplots for the suspicious features adding the upper and lower limits\n",
    "for graphical reference:\n",
    "'''\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "data = dataset[features_high_std]\n",
    "\n",
    "# Loop through each feature and create a subplot\n",
    "for i, feature in enumerate(features_high_std, 1):\n",
    "    plt.subplot(len(features_high_std), 1, i)  # Arrange subplots vertically\n",
    "    sns.boxplot(data=data[feature], orient='h')  # Set orientation to horizontal\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    \n",
    "    # Red line for the upper threshold\n",
    "    plt.axvline(x=temp_limits_upper[i - 1], color='red', linestyle='-', label='Threshold')\n",
    "    \n",
    "    # Ged line for the lower threshold\n",
    "    if temp_limits_lower[i - 1] > 0:\n",
    "           plt.axvline(x=temp_limits_lower[i - 1], color='green', linestyle='-', label='Threshold') \n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the number of data-points above the thresholds for each abnormal variance column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two new columns to the suspicious_features_boundaries DataFrame\n",
    "suspicious_features_boundaries['Above upper limits'] = [\n",
    "    data[feature][data[feature] > suspicious_features_boundaries.loc[i, 'Upper Limit']].count()\n",
    "    for i, feature in enumerate(suspicious_features_boundaries['Feature'])\n",
    "]\n",
    "\n",
    "suspicious_features_boundaries['Below lower limits'] = [\n",
    "    data[feature][data[feature] < suspicious_features_boundaries.loc[i, 'Lower Limit']].count()\n",
    "    for i, feature in enumerate(suspicious_features_boundaries['Feature'])\n",
    "]\n",
    "\n",
    "# Display the DataFrame\n",
    "suspicious_features_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing or replacing outliers\n",
    "\n",
    "For now, we replace the outliers with NaN values. This approach allows us to retain the flexibility to either remove these entries or handle them differently in subsequent steps, depending on the requirements of the analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing with NaN\n",
    "\n",
    "for index, row in suspicious_features_boundaries.iterrows():\n",
    "    feature = row['Feature']\n",
    "    upper_limit = row['Upper Limit']\n",
    "    lower_limit = row['Lower Limit']\n",
    "    dataset.loc[(dataset[feature] > upper_limit) | (dataset[feature] < lower_limit), feature] = np.nan\n",
    "\n",
    "#Â counting the number of missing values in each column\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLDL and TG\n",
    "Since VLDL is a value typically synthetic, we investigate its distribution in relation to TG. The scatter plot below highlights their relationship, showing a positive correlation between the two variables.\n",
    "\n",
    "VLDL can also be measured directly in some cases, thus the relation with the TG value can be non-linear in some cases.\n",
    "\n",
    "Formulas for computing VLDL starting from TG:\n",
    "$$VLDL = \\frac{\\text{TG}}{5} \\quad \\text{(mg/dL)}$$ \n",
    "$$VLDL = \\frac{\\text{TG}}{2.2} \\quad \\text{(mmol/L)}$$\n",
    "\n",
    "#### Conversion rate between different units of measurement:\n",
    "- (TG):\n",
    "\n",
    "$$\\text{mmol/L} = \\frac{\\text{mg/dL}}{88.5}$$\n",
    "$$\\text{mg/dL} = \\text{mmol/L} \\times 88.5$$\n",
    "\n",
    "- Cholesterol (LDL, HDL, VLDL, Totale):\n",
    "\n",
    "$$\\text{mmol/L} = \\frac{\\text{mg/dL}}{38.67}$$\n",
    "$$\\text{mg/dL} = \\text{mmol/L} \\times 38.67$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for TG vs VLDL with color based on threshold\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create a standalone pandas Series to classify points based on the threshold\n",
    "VLDL_thresh_status = pd.Series(np.where(dataset['VLDL'] > 4, 'above', 'below'), index=dataset.index)\n",
    "\n",
    "\n",
    "\n",
    "# Scatter plot with color coding\n",
    "sns.scatterplot(data=dataset, x='TG', y='VLDL', hue=VLDL_thresh_status, alpha=0.5)\n",
    "\n",
    "plt.title('Scatter Plot: TG vs VLDL')\n",
    "plt.xlabel('TG')\n",
    "plt.ylabel('VLDL')\n",
    "plt.axhline(y=4, color='red', linestyle='--', label='Hypothesis Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for VLDL values under 4\n",
    "filtered_dataset = dataset[dataset['VLDL'] < 4]\n",
    "\n",
    "# Scatter plot for TG vs VLDL with VLDL < 4\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.scatterplot(data=filtered_dataset, x='TG', y='VLDL', alpha=0.5, hue=VLDL_thresh_status)\n",
    "plt.title('Scatter Plot: TG vs VLDL (VLDL < 4)')\n",
    "plt.xlabel('TG')\n",
    "plt.ylabel('VLDL')\n",
    "\n",
    "# Plot the line y = x / 2.2\n",
    "x_vals = np.linspace(filtered_dataset['TG'].min(), filtered_dataset['TG'].max(), 100)\n",
    "y_vals = x_vals / 2.2\n",
    "plt.plot(x_vals, y_vals, color='red', label='VLDL = TG / 2.2')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for VLDL values over 4\n",
    "filtered_dataset = dataset[dataset['VLDL'] >= 4]\n",
    "\n",
    "# Scatter plot for TG vs VLDL with VLDL >= 4\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.scatterplot(data=filtered_dataset, x='TG', y='VLDL', alpha=0.5, hue=VLDL_thresh_status)\n",
    "plt.title('Scatter Plot: TG vs VLDL (VLDL >= 4)')\n",
    "plt.xlabel('TG')\n",
    "plt.ylabel('VLDL')\n",
    "plt.grid(True)\n",
    "\n",
    "x_vals = np.linspace(filtered_dataset['TG'].min(), filtered_dataset['TG'].max(), 100)\n",
    "y_vals = x_vals * 38.67 / 5.5\n",
    "plt.plot(x_vals, y_vals, color='red', label='VLDL = TG * 38.67 / 5.5')\n",
    "plt.legend()\n",
    "\n",
    "# VLDL = TG * 38.67 / 5.5\n",
    "# TG = VLDL * 5.5 / 38.67\n",
    "#Â converted_VLDL = (VLDL * 5.5 / 38.67) / 2.2\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are two groups of VLDL values, as seen in the graphs above. \n",
    "\n",
    "- One group consists of values less than 4, following a pseudo-linear distribution composed of synthetic values derived from the standard formula ($VLDL = TG / 2.2$) with the unit of measurement: mmol/L. \n",
    "- The other group exhibits an apparently incorrect trend. Further analysis has demonstrated that the second group represents measurements in a different unit of measurement (mg/dL). \n",
    "\n",
    "To homogenize the data, it will be necessary to convert the VLDL measurements back to TG and re-compute the VLDL value as in the other group:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert VLDL values greater than 4 using the new formula\n",
    "dataset.loc[dataset['VLDL'] > 4, 'VLDL'] = (dataset['VLDL'] * 5.5 / 38.67) / 2.2\n",
    "\n",
    "# Scatter plot for TG vs VLDL after conversion\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.scatterplot(data=dataset, x='TG', y='VLDL', alpha=0.5)\n",
    "plt.title('Scatter Plot: TG vs VLDL (After Conversion)')\n",
    "plt.xlabel('TG')\n",
    "plt.ylabel('VLDL')\n",
    "\n",
    "# Plot the line y = x / 2.2\n",
    "x_vals = np.linspace(dataset['TG'].min(), dataset['TG'].max(), 100)\n",
    "y_vals = x_vals / 2.2\n",
    "plt.plot(x_vals, y_vals, color='red', label='VLDL = TG / 2.2')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows with one or more NaN values\n",
    "rows_with_nan = dataset.isnull().any(axis=1).sum()\n",
    "\n",
    "# Calculate the percentage of rows with NaN values\n",
    "percentage_with_nan = (rows_with_nan / len(dataset)) * 100\n",
    "\n",
    "print(f\"Number of rows with NaN values: {rows_with_nan}\")\n",
    "print(f\"Percentage of rows with NaN values: {percentage_with_nan:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('../datasets/diabetes_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
